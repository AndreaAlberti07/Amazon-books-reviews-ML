{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import nltk\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# Initialize spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"MultinomialNBC\").getOrCreate()\n",
    "\n",
    "# Define the schema\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"Price\", FloatType(), True),\n",
    "    StructField(\"User_id\", IntegerType(), True),\n",
    "    StructField(\"profileName\", StringType(), True),\n",
    "    StructField(\"review/score\", FloatType(), True),\n",
    "    StructField(\"review/time\", IntegerType(), True),\n",
    "    StructField(\"review/summary\", StringType(), True),\n",
    "    StructField(\"review/text\", StringType(), True),\n",
    "    StructField(\"N_helpful\", IntegerType(), True),\n",
    "    StructField(\"Tot_votes\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Load your DataFrame (assuming you have it in a variable df)\n",
    "# Load the data\n",
    "df_ratings = spark.read.csv('hdfs://localhost:9900/user/book_reviews/books_rating_cleaned.csv', header=True, schema=ratings_schema, sep='\\t')\n",
    "df_ratings.show(5)\n",
    "\n",
    "# Filter out the data\n",
    "df_ratings_filtered = df_ratings.filter(df_ratings['review/text'].isNotNull())\n",
    "df_ratings_filtered = df_ratings_filtered.filter(df_ratings_filtered['review/score'] != 3)\n",
    "df_ratings_filtered = df_ratings_filtered.filter(df_ratings_filtered['Tot_votes'] != 0)\n",
    "\n",
    "# Add the helpfulness ratio column\n",
    "df_ratings_filtered = df_ratings_filtered.withColumn('helpfulness_ratio', df_ratings_filtered['N_helpful']/df_ratings_filtered['Tot_votes']*sqrt(df_ratings_filtered['Tot_votes']))\n",
    "\n",
    "# Add the class column\n",
    "df_ratings_filtered = df_ratings_filtered.withColumn('class', when(df_ratings_filtered['review/score'] >= 4, 1).otherwise(0))\n",
    "\n",
    "# Retain only the required columns\n",
    "df_ratings_selected = df_ratings_filtered.select('review/text', 'helpfulness_ratio', 'class')\n",
    "df_ratings_selected.show(5)\n",
    "\n",
    "# Select relevant columns and handle missing values\n",
    "df = df_ratings_selected.select(\"class\", \"review/text\").na.drop()\n",
    "\n",
    "# Tokenize the 'review/text' column\n",
    "tokenizer = Tokenizer(inputCol=\"review/text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(df)\n",
    "\n",
    "# Apply TF-IDF to convert text data to numerical features\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=2000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(hashingTF.transform(wordsData))\n",
    "rescaledData = idfModel.transform(hashingTF.transform(wordsData))\n",
    "\n",
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "(trainingData, testData) = rescaledData.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "# Create and train a Multinomial Naive Bayes classifier\n",
    "nb = NaiveBayes(labelCol=\"class\", featuresCol=\"features\", smoothing=1.0, modelType=\"multinomial\")\n",
    "model = nb.fit(trainingData)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"class\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version using BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import nltk\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# Initialize spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"MultinomialNBC\").getOrCreate()\n",
    "\n",
    "# Define the schema\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"Price\", FloatType(), True),\n",
    "    StructField(\"User_id\", IntegerType(), True),\n",
    "    StructField(\"profileName\", StringType(), True),\n",
    "    StructField(\"review/score\", FloatType(), True),\n",
    "    StructField(\"review/time\", IntegerType(), True),\n",
    "    StructField(\"review/summary\", StringType(), True),\n",
    "    StructField(\"review/text\", StringType(), True),\n",
    "    StructField(\"N_helpful\", IntegerType(), True),\n",
    "    StructField(\"Tot_votes\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Load your DataFrame (assuming you have it in a variable df)\n",
    "# Load the data\n",
    "df_ratings = spark.read.csv('hdfs://localhost:9900/user/book_reviews/books_rating_cleaned.csv', header=True, schema=ratings_schema, sep='\\t')\n",
    "df_ratings.show(5)\n",
    "\n",
    "# Filter out the data\n",
    "df_ratings_filtered = df_ratings.filter(df_ratings['review/text'].isNotNull())\n",
    "df_ratings_filtered = df_ratings_filtered.filter(df_ratings_filtered['review/score'] != 3)\n",
    "df_ratings_filtered = df_ratings_filtered.filter(df_ratings_filtered['Tot_votes'] != 0)\n",
    "\n",
    "# Add the helpfulness ratio column\n",
    "df_ratings_filtered = df_ratings_filtered.withColumn('helpfulness_ratio', df_ratings_filtered['N_helpful']/df_ratings_filtered['Tot_votes']*sqrt(df_ratings_filtered['Tot_votes']))\n",
    "\n",
    "# Add the class column\n",
    "df_ratings_filtered = df_ratings_filtered.withColumn('class', when(df_ratings_filtered['review/score'] >= 4, 1).otherwise(0))\n",
    "\n",
    "# Retain only the required columns\n",
    "df_ratings_selected = df_ratings_filtered.select('review/text', 'helpfulness_ratio', 'class')\n",
    "df_ratings_selected.show(5)\n",
    "\n",
    "# Select relevant columns and handle missing values\n",
    "df = df_ratings_selected.select(\"class\", \"review/text\").na.drop()\n",
    "\n",
    "\n",
    "# Tokenize the 'review/text' column\n",
    "tokenizer = Tokenizer(inputCol=\"review/text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(df)\n",
    "\n",
    "# Apply Bag of Words (BoW) to convert text data to numerical features\n",
    "vectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "model_cv = vectorizer.fit(wordsData)\n",
    "rescaledData = model_cv.transform(wordsData)\n",
    "\n",
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "(trainingData, testData) = rescaledData.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "# Create and train a Multinomial Naive Bayes classifier\n",
    "nb = NaiveBayes(labelCol=\"class\", featuresCol=\"features\", smoothing=1.0, modelType=\"multinomial\")\n",
    "model_nb = nb.fit(trainingData)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = model_nb.transform(testData)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"class\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible implementation to count the words (TO CHECK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreaalberti/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "23/09/21 18:00:53 WARN Utils: Your hostname, MacBook-Pro-di-Andrea.local resolves to a loopback address: 127.0.0.1; using 192.168.1.148 instead (on interface en0)\n",
      "23/09/21 18:00:53 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/21 18:00:53 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------+--------------------+------------+-----------+--------------------+--------------------+---------+---------+\n",
      "|               Title|Price|User_id|         profileName|review/score|review/time|      review/summary|         review/text|N_helpful|Tot_votes|\n",
      "+--------------------+-----+-------+--------------------+------------+-----------+--------------------+--------------------+---------+---------+\n",
      "|'Its Only Art If ...| null|   null|Jim of Oz \"jim-of...|         4.0|  940636800|Nice collection o...|This is only for ...|        7|        7|\n",
      "|'Dr. Seuss: Ameri...| null|   null|       Kevin Killian|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|       10|       10|\n",
      "|'Dr. Seuss: Ameri...| null|   null|        John Granger|         5.0| 1078790400|Essential for eve...|If people become ...|       10|       11|\n",
      "|'Dr. Seuss: Ameri...| null|   null|Roy E. Perry \"ama...|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|        7|        7|\n",
      "|'Dr. Seuss: Ameri...| null|   null|D. H. Richards \"n...|         4.0| 1107993600|Good academic ove...|Philip Nel - Dr. ...|        3|        3|\n",
      "+--------------------+-----+-------+--------------------+------------+-----------+--------------------+--------------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+------------------+-----+\n",
      "|         review/text| helpfulness_ratio|class|\n",
      "+--------------------+------------------+-----+\n",
      "|This is only for ...|2.6457513110645907|    1|\n",
      "|I don't care much...|3.1622776601683795|    1|\n",
      "|If people become ...| 3.015113445777636|    1|\n",
      "|Theodore Seuss Ge...|2.6457513110645907|    1|\n",
      "|Philip Nel - Dr. ...|1.7320508075688772|    1|\n",
      "+--------------------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java HotSpot(TM) 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeCache: size=131072Kb used=22902Kb max_used=24185Kb free=108169Kb\n",
      " bounds [0x000000010a1d8000, 0x000000010b998000, 0x00000001121d8000]\n",
      " total_blobs=9423 nmethods=8434 adapters=902\n",
      " compilation: disabled (not enough contiguous free space left)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/21 18:02:07 WARN MemoryStore: Not enough space to cache rdd_17_11 in memory! (computed 15.3 MiB so far)\n",
      "23/09/21 18:02:07 WARN BlockManager: Persisting block rdd_17_11 to disk instead.\n",
      "23/09/21 18:02:07 WARN MemoryStore: Not enough space to cache rdd_17_12 in memory! (computed 13.5 MiB so far)\n",
      "23/09/21 18:02:07 WARN BlockManager: Persisting block rdd_17_12 to disk instead.\n",
      "23/09/21 18:02:18 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "23/09/21 18:03:07 WARN DAGScheduler: Broadcasting large task binary with size 2.9 MiB\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>book</td>\n",
       "      <td>-4.033910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>read</td>\n",
       "      <td>-4.877841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>one</td>\n",
       "      <td>-4.920655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>like</td>\n",
       "      <td>-5.419392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story</td>\n",
       "      <td>-5.570671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>soldiers</td>\n",
       "      <td>-9.490721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2113</th>\n",
       "      <td>plans</td>\n",
       "      <td>-9.491529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1818</th>\n",
       "      <td>gotten</td>\n",
       "      <td>-9.491731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>mass</td>\n",
       "      <td>-9.491832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1931</th>\n",
       "      <td>acts</td>\n",
       "      <td>-9.492844</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          word      prob\n",
       "0         book -4.033910\n",
       "1         read -4.877841\n",
       "2          one -4.920655\n",
       "3         like -5.419392\n",
       "4        story -5.570671\n",
       "...        ...       ...\n",
       "2059  soldiers -9.490721\n",
       "2113     plans -9.491529\n",
       "1818    gotten -9.491731\n",
       "1995      mass -9.491832\n",
       "1931      acts -9.492844\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import nltk\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# Initialize spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "# Import necessary libraries\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, CountVectorizer\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"MultinomialNBC\").getOrCreate()\n",
    "\n",
    "# Define the schema\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"Price\", FloatType(), True),\n",
    "    StructField(\"User_id\", IntegerType(), True),\n",
    "    StructField(\"profileName\", StringType(), True),\n",
    "    StructField(\"review/score\", FloatType(), True),\n",
    "    StructField(\"review/time\", IntegerType(), True),\n",
    "    StructField(\"review/summary\", StringType(), True),\n",
    "    StructField(\"review/text\", StringType(), True),\n",
    "    StructField(\"N_helpful\", IntegerType(), True),\n",
    "    StructField(\"Tot_votes\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Load your DataFrame (assuming you have it in a variable df)\n",
    "# Load the data\n",
    "df_ratings = spark.read.csv('hdfs://localhost:9900/user/book_reviews/books_rating_cleaned.csv', header=True, schema=ratings_schema, sep='\\t')\n",
    "df_ratings.show(5)\n",
    "\n",
    "# Filter out the data\n",
    "df_ratings_filtered = df_ratings.filter(df_ratings['review/text'].isNotNull())\n",
    "df_ratings_filtered = df_ratings_filtered.filter(df_ratings_filtered['review/score'] != 3)\n",
    "df_ratings_filtered = df_ratings_filtered.filter(df_ratings_filtered['Tot_votes'] != 0)\n",
    "\n",
    "# Add the helpfulness ratio column\n",
    "df_ratings_filtered = df_ratings_filtered.withColumn('helpfulness_ratio', df_ratings_filtered['N_helpful']/df_ratings_filtered['Tot_votes']*sqrt(df_ratings_filtered['Tot_votes']))\n",
    "\n",
    "# Add the class column\n",
    "df_ratings_filtered = df_ratings_filtered.withColumn('class', when(df_ratings_filtered['review/score'] >= 4, 1).otherwise(0))\n",
    "\n",
    "# Retain only the required columns\n",
    "df_ratings_selected = df_ratings_filtered.select('review/text', 'helpfulness_ratio', 'class')\n",
    "df_ratings_selected.show(5)\n",
    "\n",
    "# Select relevant columns and handle missing values\n",
    "df = df_ratings_selected.select(\"class\", \"review/text\").na.drop()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Tokenize the 'review/text' column\n",
    "tokenizer = Tokenizer(inputCol=\"review/text\", outputCol=\"words\")\n",
    "\n",
    "# Remove stopwords\n",
    "stop_words_remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered_words\")\n",
    "\n",
    "# Convert words to a BoW feature vector\n",
    "vectorizer = CountVectorizer(inputCol=\"filtered_words\", outputCol=\"features\")\n",
    "\n",
    "# Create a Naive Bayes model\n",
    "nb = NaiveBayes(labelCol=\"class\", featuresCol=\"features\", predictionCol=\"prediction\")\n",
    "\n",
    "# Create a pipeline\n",
    "pipeline = Pipeline(stages=[tokenizer, stop_words_remover, vectorizer, nb])\n",
    "\n",
    "\n",
    "# Fit the pipeline on your data\n",
    "model = pipeline.fit(df)\n",
    "\n",
    "# Fit the Multinomial Naive Bayes model on the training data\n",
    "nb_model = model.stages[-1]\n",
    "\n",
    "# Get the vocabulary\n",
    "vocabulary = model.stages[2].vocabulary\n",
    "\n",
    "# Get the word probabilities for class 1\n",
    "class_1_probs = nb_model.theta.toArray()[1]\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "results = pd.DataFrame({'word': vocabulary, 'prob': class_1_probs})\n",
    "\n",
    "# Sort the DataFrame by descending word probabilities and take top 2000\n",
    "results = results.sort_values(by='prob', ascending=False).head(2000)\n",
    "results\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
