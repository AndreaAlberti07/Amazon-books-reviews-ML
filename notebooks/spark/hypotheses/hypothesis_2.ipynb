{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreaalberti/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------+--------------------+------------+-----------+--------------------+--------------------+---------+---------+\n",
      "|               Title|Price|User_id|         profileName|review/score|review/time|      review/summary|         review/text|N_helpful|Tot_votes|\n",
      "+--------------------+-----+-------+--------------------+------------+-----------+--------------------+--------------------+---------+---------+\n",
      "|'Its Only Art If ...| null|   null|Jim of Oz \"jim-of...|         4.0|  940636800|Nice collection o...|This is only for ...|        7|        7|\n",
      "|'Dr. Seuss: Ameri...| null|   null|       Kevin Killian|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|       10|       10|\n",
      "|'Dr. Seuss: Ameri...| null|   null|        John Granger|         5.0| 1078790400|Essential for eve...|If people become ...|       10|       11|\n",
      "|'Dr. Seuss: Ameri...| null|   null|Roy E. Perry \"ama...|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|        7|        7|\n",
      "|'Dr. Seuss: Ameri...| null|   null|D. H. Richards \"n...|         4.0| 1107993600|Good academic ove...|Philip Nel - Dr. ...|        3|        3|\n",
      "+--------------------+-----+-------+--------------------+------------+-----------+--------------------+--------------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+------------------+-----+\n",
      "|         review/text| helpfulness_ratio|class|\n",
      "+--------------------+------------------+-----+\n",
      "|This is only for ...|2.6457513110645907|    1|\n",
      "|I don't care much...|3.1622776601683795|    1|\n",
      "|If people become ...| 3.015113445777636|    1|\n",
      "|Theodore Seuss Ge...|2.6457513110645907|    1|\n",
      "|Philip Nel - Dr. ...|1.7320508075688772|    1|\n",
      "+--------------------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java HotSpot(TM) 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeCache: size=131072Kb used=29464Kb max_used=29548Kb free=101607Kb\n",
      " bounds [0x000000010a9d8000, 0x000000010c708000, 0x00000001129d8000]\n",
      " total_blobs=11831 nmethods=10765 adapters=977\n",
      " compilation: disabled (not enough contiguous free space left)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/09/21 11:56:49 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "[Stage 7:===================================================>     (19 + 2) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.796588805977923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import nltk\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# Initialize spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"MultinomialNBC\").getOrCreate()\n",
    "\n",
    "# Define the schema\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"Price\", FloatType(), True),\n",
    "    StructField(\"User_id\", IntegerType(), True),\n",
    "    StructField(\"profileName\", StringType(), True),\n",
    "    StructField(\"review/score\", FloatType(), True),\n",
    "    StructField(\"review/time\", IntegerType(), True),\n",
    "    StructField(\"review/summary\", StringType(), True),\n",
    "    StructField(\"review/text\", StringType(), True),\n",
    "    StructField(\"N_helpful\", IntegerType(), True),\n",
    "    StructField(\"Tot_votes\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Load your DataFrame (assuming you have it in a variable df)\n",
    "# Load the data\n",
    "df_ratings = spark.read.csv('hdfs://localhost:9900/user/book_reviews/books_rating_cleaned.csv', header=True, schema=ratings_schema, sep='\\t')\n",
    "df_ratings.show(5)\n",
    "\n",
    "# Filter out the data\n",
    "df_ratings_filtered = df_ratings.filter(df_ratings['review/text'].isNotNull())\n",
    "df_ratings_filtered = df_ratings_filtered.filter(df_ratings_filtered['review/score'] != 3)\n",
    "df_ratings_filtered = df_ratings_filtered.filter(df_ratings_filtered['Tot_votes'] != 0)\n",
    "\n",
    "# Add the helpfulness ratio column\n",
    "df_ratings_filtered = df_ratings_filtered.withColumn('helpfulness_ratio', df_ratings_filtered['N_helpful']/df_ratings_filtered['Tot_votes']*sqrt(df_ratings_filtered['Tot_votes']))\n",
    "\n",
    "# Add the class column\n",
    "df_ratings_filtered = df_ratings_filtered.withColumn('class', when(df_ratings_filtered['review/score'] >= 4, 1).otherwise(0))\n",
    "\n",
    "# Retain only the required columns\n",
    "df_ratings_selected = df_ratings_filtered.select('review/text', 'helpfulness_ratio', 'class')\n",
    "df_ratings_selected.show(5)\n",
    "\n",
    "# Select relevant columns and handle missing values\n",
    "df = df_ratings_selected.select(\"class\", \"review/text\").na.drop()\n",
    "\n",
    "# Tokenize the 'review/text' column\n",
    "tokenizer = Tokenizer(inputCol=\"review/text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(df)\n",
    "\n",
    "# Apply TF-IDF to convert text data to numerical features\n",
    "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=2000)\n",
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(hashingTF.transform(wordsData))\n",
    "rescaledData = idfModel.transform(hashingTF.transform(wordsData))\n",
    "\n",
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "(trainingData, testData) = rescaledData.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "# Create and train a Multinomial Naive Bayes classifier\n",
    "nb = NaiveBayes(labelCol=\"class\", featuresCol=\"features\", smoothing=1.0, modelType=\"multinomial\")\n",
    "model = nb.fit(trainingData)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"class\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Version using BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/andreaalberti/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+-------+--------------------+------------+-----------+--------------------+--------------------+---------+---------+\n",
      "|               Title|Price|User_id|         profileName|review/score|review/time|      review/summary|         review/text|N_helpful|Tot_votes|\n",
      "+--------------------+-----+-------+--------------------+------------+-----------+--------------------+--------------------+---------+---------+\n",
      "|'Its Only Art If ...| null|   null|Jim of Oz \"jim-of...|         4.0|  940636800|Nice collection o...|This is only for ...|        7|        7|\n",
      "|'Dr. Seuss: Ameri...| null|   null|       Kevin Killian|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|       10|       10|\n",
      "|'Dr. Seuss: Ameri...| null|   null|        John Granger|         5.0| 1078790400|Essential for eve...|If people become ...|       10|       11|\n",
      "|'Dr. Seuss: Ameri...| null|   null|Roy E. Perry \"ama...|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|        7|        7|\n",
      "|'Dr. Seuss: Ameri...| null|   null|D. H. Richards \"n...|         4.0| 1107993600|Good academic ove...|Philip Nel - Dr. ...|        3|        3|\n",
      "+--------------------+-----+-------+--------------------+------------+-----------+--------------------+--------------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+------------------+-----+\n",
      "|         review/text| helpfulness_ratio|class|\n",
      "+--------------------+------------------+-----+\n",
      "|This is only for ...|2.6457513110645907|    1|\n",
      "|I don't care much...|3.1622776601683795|    1|\n",
      "|If people become ...| 3.015113445777636|    1|\n",
      "|Theodore Seuss Ge...|2.6457513110645907|    1|\n",
      "|Philip Nel - Dr. ...|1.7320508075688772|    1|\n",
      "+--------------------+------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:==================================================>     (19 + 2) / 21]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8365845697638484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import nltk\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "# Initialize spark\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
    "from pyspark.ml.classification import NaiveBayes\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.feature import CountVectorizer\n",
    "\n",
    "# Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"MultinomialNBC\").getOrCreate()\n",
    "\n",
    "# Define the schema\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"Price\", FloatType(), True),\n",
    "    StructField(\"User_id\", IntegerType(), True),\n",
    "    StructField(\"profileName\", StringType(), True),\n",
    "    StructField(\"review/score\", FloatType(), True),\n",
    "    StructField(\"review/time\", IntegerType(), True),\n",
    "    StructField(\"review/summary\", StringType(), True),\n",
    "    StructField(\"review/text\", StringType(), True),\n",
    "    StructField(\"N_helpful\", IntegerType(), True),\n",
    "    StructField(\"Tot_votes\", IntegerType(), True)\n",
    "])\n",
    "\n",
    "# Load your DataFrame (assuming you have it in a variable df)\n",
    "# Load the data\n",
    "df_ratings = spark.read.csv('hdfs://localhost:9900/user/book_reviews/books_rating_cleaned.csv', header=True, schema=ratings_schema, sep='\\t')\n",
    "df_ratings.show(5)\n",
    "\n",
    "# Filter out the data\n",
    "df_ratings_filtered = df_ratings.filter(df_ratings['review/text'].isNotNull())\n",
    "df_ratings_filtered = df_ratings_filtered.filter(df_ratings_filtered['review/score'] != 3)\n",
    "df_ratings_filtered = df_ratings_filtered.filter(df_ratings_filtered['Tot_votes'] != 0)\n",
    "\n",
    "# Add the helpfulness ratio column\n",
    "df_ratings_filtered = df_ratings_filtered.withColumn('helpfulness_ratio', df_ratings_filtered['N_helpful']/df_ratings_filtered['Tot_votes']*sqrt(df_ratings_filtered['Tot_votes']))\n",
    "\n",
    "# Add the class column\n",
    "df_ratings_filtered = df_ratings_filtered.withColumn('class', when(df_ratings_filtered['review/score'] >= 4, 1).otherwise(0))\n",
    "\n",
    "# Retain only the required columns\n",
    "df_ratings_selected = df_ratings_filtered.select('review/text', 'helpfulness_ratio', 'class')\n",
    "df_ratings_selected.show(5)\n",
    "\n",
    "# Select relevant columns and handle missing values\n",
    "df = df_ratings_selected.select(\"class\", \"review/text\").na.drop()\n",
    "\n",
    "\n",
    "# Tokenize the 'review/text' column\n",
    "tokenizer = Tokenizer(inputCol=\"review/text\", outputCol=\"words\")\n",
    "wordsData = tokenizer.transform(df)\n",
    "\n",
    "# Apply Bag of Words (BoW) to convert text data to numerical features\n",
    "vectorizer = CountVectorizer(inputCol=\"words\", outputCol=\"features\", vocabSize=10000, minDF=5)\n",
    "model = vectorizer.fit(wordsData)\n",
    "rescaledData = model.transform(wordsData)\n",
    "\n",
    "# Split the data into training and testing sets (70% training, 30% testing)\n",
    "(trainingData, testData) = rescaledData.randomSplit([0.7, 0.3], seed=123)\n",
    "\n",
    "# Create and train a Multinomial Naive Bayes classifier\n",
    "nb = NaiveBayes(labelCol=\"class\", featuresCol=\"features\", smoothing=1.0, modelType=\"multinomial\")\n",
    "model = nb.fit(trainingData)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "predictions = model.transform(testData)\n",
    "\n",
    "# Evaluate the model\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"class\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible implementation to count the words (TO CHECK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import IntegerType\n",
    "\n",
    "# Assuming you've already trained the MNB model and have 'predictions' DataFrame\n",
    "\n",
    "# Define a UDF to count positive words based on model predictions\n",
    "def count_positive_words(predictions):\n",
    "    positive_predictions = predictions.filter(predictions.prediction == 1)\n",
    "    return len(positive_predictions)\n",
    "\n",
    "# Register the UDF\n",
    "count_positive_words_udf = udf(count_positive_words, IntegerType())\n",
    "\n",
    "# Add a new column 'positive_word_count' to your DataFrame\n",
    "df_with_positive_word_count = df.withColumn('positive_word_count', count_positive_words_udf(predictions))\n",
    "\n",
    "# Show the DataFrame with the new column\n",
    "df_with_positive_word_count.select(\"review/text\", \"positive_word_count\").show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
