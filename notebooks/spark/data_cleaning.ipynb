{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning with spark\n",
    "### in this notebook the useless columns will be removed\n",
    "\n",
    "### **PLEASE NOTE :**  \n",
    "### Since this script stores the results in hadoop, execute it only once, otherwise an error will be thrown\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import pyspark as ps\n",
    "from pyspark.sql.functions import col, sum\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, FloatType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lit\n",
    "import findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/05 17:44:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Locate the spark installation\n",
    "findspark.init()\n",
    "\n",
    "# Initialize a SparkContext\n",
    "spark = SparkSession.builder.appName(\"data_cleaning\").getOrCreate()\n",
    "spark.stop()\n",
    "sc = ps.SparkContext(appName=\"data_cleaning\")\n",
    "\n",
    "# Initialize the Session\n",
    "spark_session = ps.sql.SparkSession(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect and import data from HDFS directly into a Spark DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define schema for better manipulation\n",
    "\n",
    "data_schema = StructType([\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"description\", StringType(), True),\n",
    "    StructField(\"authors\", StringType(), True),\n",
    "    StructField(\"image\", StringType(), True),\n",
    "    StructField(\"previewLink\", StringType(), True),\n",
    "    StructField(\"publisher\", StringType(), True),\n",
    "    StructField(\"publishedDate\", StringType(), True),\n",
    "    StructField(\"infoLink\", StringType(), True),\n",
    "    StructField(\"categories\", StringType(), True),\n",
    "    StructField(\"ratingsCount\", FloatType(), True)\n",
    "])\n",
    "\n",
    "ratings_schema = StructType([\n",
    "    StructField(\"Id\", IntegerType(), True),\n",
    "    StructField(\"Title\", StringType(), True),\n",
    "    StructField(\"Price\", FloatType(), True),\n",
    "    StructField(\"User_id\", IntegerType(), True),\n",
    "    StructField(\"profileName\", StringType(), True),\n",
    "    StructField(\"review/helpfulness\", StringType(), True),\n",
    "    StructField(\"review/score\", FloatType(), True),\n",
    "    StructField(\"review/time\", IntegerType(), True),\n",
    "    StructField(\"review/summary\", StringType(), True),\n",
    "    StructField(\"review/text\", StringType(), True)\n",
    "])\n",
    "\n",
    "# Load the original data\n",
    "\n",
    "df_data = spark_session.read.option('escape', '\"').csv(\n",
    "    'hdfs://localhost:9900/user/book_reviews/original_data/books_data.csv', header=True, schema=data_schema)\n",
    "df_ratings = spark_session.read.option('escape', '\"').csv(\n",
    "    'hdfs://localhost:9900/user/book_reviews/original_data/books_rating.csv', header=True, schema=ratings_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations\n",
    "---\n",
    "\n",
    "### - Remove useless columns\n",
    "\n",
    "These are the columns whcih are not useful for our analysis. The original files are kept unchanged in HDFS, and the new files are stored in HDFS as well.\n",
    "\n",
    "**Data Table:**\n",
    "All the links are removed.\n",
    "- image\n",
    "- previewLink\n",
    "- infoLink\n",
    "- ratingsCount\n",
    "\n",
    "**Rating Table:**\n",
    "- id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+---------+-------------+--------------------+\n",
      "|               Title|         description|            authors|publisher|publishedDate|          categories|\n",
      "+--------------------+--------------------+-------------------+---------+-------------+--------------------+\n",
      "|Its Only Art If I...|                null|   ['Julie Strain']|     null|         1996|['Comics & Graphi...|\n",
      "|Dr. Seuss: Americ...|Philip Nel takes ...|     ['Philip Nel']|A&C Black|   2005-01-01|['Biography & Aut...|\n",
      "|Wonderful Worship...|This resource inc...|   ['David R. Ray']|     null|         2000|        ['Religion']|\n",
      "|Whispers of the W...|Julia Thomas find...|['Veronica Haddon']|iUniverse|      2005-02|         ['Fiction']|\n",
      "|Nation Dance: Rel...|                null|    ['Edward Long']|     null|   2003-03-01|                null|\n",
      "+--------------------+--------------------+-------------------+---------+-------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----+-------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|               Title|Price|User_id|         profileName|review/helpfulness|review/score|review/time|      review/summary|         review/text|\n",
      "+--------------------+-----+-------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "|Its Only Art If I...| null|   null|Jim of Oz \"jim-of...|               7/7|         4.0|  940636800|Nice collection o...|This is only for ...|\n",
      "|Dr. Seuss: Americ...| null|   null|       Kevin Killian|             10/10|         5.0| 1095724800|   Really Enjoyed It|I don't care much...|\n",
      "|Dr. Seuss: Americ...| null|   null|        John Granger|             10/11|         5.0| 1078790400|Essential for eve...|If people become ...|\n",
      "|Dr. Seuss: Americ...| null|   null|Roy E. Perry \"ama...|               7/7|         4.0| 1090713600|Phlip Nel gives s...|Theodore Seuss Ge...|\n",
      "|Dr. Seuss: Americ...| null|   null|D. H. Richards \"n...|               3/3|         4.0| 1107993600|Good academic ove...|Philip Nel - Dr. ...|\n",
      "+--------------------+-----+-------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove image column from data\n",
    "df_data = df_data.drop(df_data.image)\n",
    "\n",
    "# Remove previewLink column from data\n",
    "df_data = df_data.drop(df_data.previewLink)\n",
    "\n",
    "# Remove infoLink column from data\n",
    "df_data = df_data.drop(df_data.infoLink)\n",
    "\n",
    "# Remove ratingsCount column from data\n",
    "df_data = df_data.drop(df_data.ratingsCount)\n",
    "\n",
    "# Show the results\n",
    "df_data.show(5)\n",
    "\n",
    "# Remove Id column from ratings data\n",
    "df_ratings = df_ratings.drop(df_ratings.Id)\n",
    "\n",
    "# Show the results\n",
    "df_ratings.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Remove all the punctuation inside each column\n",
    "\n",
    "This is to avoid parsing problem when the csv in read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, sum, regexp_replace\n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "\n",
    "data_cols_to_change = ['Title', 'description', 'authors', 'publisher', 'categories']\n",
    "for col_name in data_cols_to_change:\n",
    "    df_data = df_data.withColumn(col_name, regexp_replace(col(col_name), r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\\\\\]^_`{|}~]', ' '))\n",
    "\n",
    "ratings_cols_to_change = ['Title','profileName', 'review/summary', 'review/text']\n",
    "for col_name in ratings_cols_to_change:\n",
    "    df_ratings = df_ratings.withColumn(col_name, regexp_replace(col(col_name), r'[!\"#$%&\\'()*+,-./:;<=>?@\\[\\\\\\]^_`{|}~]', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:============================================>            (17 + 5) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does the 'name' column contain 'A'?  False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Check if a given column contains a given character\n",
    "'''\n",
    "contains_A = df_ratings.filter(col(\"User_id\").contains(\",\")).count() > 0\n",
    "print(\"Does the 'name' column contain 'A'? \", contains_A)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store the results in hadoop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java HotSpot(TM) 64-Bit Server VM warning: CodeCache is full. Compiler has been disabled.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: Try increasing the code cache size using -XX:ReservedCodeCacheSize=\n",
      "[Stage 2:>                                                         (0 + 8) / 22]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CodeCache: size=131072Kb used=20651Kb max_used=20663Kb free=110420Kb\n",
      " bounds [0x00000001061d8000, 0x0000000107628000, 0x000000010e1d8000]\n",
      " total_blobs=8419 nmethods=7455 adapters=877\n",
      " compilation: disabled (not enough contiguous free space left)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_ratings.repartition(1).write.option('escape', '\"').csv(\n",
    "    'hdfs://localhost:9900/user/book_reviews/books_rating', mode='overwrite', header=True)\n",
    "\n",
    "df_data.repartition(1).write.option('escape', '\"').csv(\n",
    "    'hdfs://localhost:9900/user/book_reviews/books_data', mode='overwrite', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Check whether the columns has been correctly removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_df = spark_session.read.option('escape', '\"').csv(\n",
    "    'hdfs://localhost:9900/user/book_reviews/books_rating.csv', header=True, inferSchema=True)\n",
    "ratings_df.printSchema()\n",
    "ratings_df.describe().show()\n",
    "ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = spark_session.read.option('escape', '\"').csv(\n",
    "    'hdfs://localhost:9900/user/book_reviews/books_data.csv', header=True, inferSchema=True)\n",
    "data_df.printSchema()\n",
    "data_df.describe().show()\n",
    "data_df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_session.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
